{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fb70680-ffd7-4a24-96a5-3dbc83e41ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "953233a3-ced8-4766-a424-e23fe0116646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec67e36d-fe6b-4654-b5ae-de72c46b92ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45e20aa6-a4c3-4327-aa0d-7b8795958855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "271562e1-8f11-40a1-8b2d-8324d83cb14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6aa19ac1-b5c2-4293-80b1-cda67ee93cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dce64931-8a21-42a7-8021-3775a356ea58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e5a401786849d892cac19f6e0d62f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff1762734674a04b9445a068643916a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e88199220d4e0ba5f14c86cf51f5ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba94443007ac4b73816dbf0237d6b76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e8b4d6-716c-486c-8d2f-37509bb3ff31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a54aa8ef-c5d0-494d-95e3-c4a8809787cc",
   "metadata": {},
   "source": [
    "### Discrimination Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4ffc9d-7496-4900-8610-240d331ad7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0787db-6359-439f-abcc-c8393c605581",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fill_masks(sentence, targets):\n",
    "        new_sentence = sentence\n",
    "        for target in targets:\n",
    "            new_sentence = re.sub('MASK',target,new_sentence, count=1)\n",
    "        #print(\"FILLED MASK:\", new_sentence)\n",
    "        return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8e1ac15a-5860-4804-b3ae-bacb369a3fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_file(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df['Target_Stereotypical'] = df['Target_Stereotypical'].apply(lambda x: x.replace(\"'\", \"\").replace('[', '').replace(']','').split(','))\n",
    "    df['Target_Anti-Stereotypical'] = df['Target_Anti-Stereotypical'].apply(lambda x: x.replace(\"'\", \"\").replace('[', '').replace(']','').split(','))\n",
    "    df['Stereotypical'] = df.apply(lambda x: fill_masks(x['Sentence'],x['Target_Stereotypical']),axis=1)\n",
    "    df['Anti-Stereotypical'] = df.apply(lambda x: fill_masks(x['Sentence'],x['Target_Anti-Stereotypical']),axis=1)\n",
    "    return df\n",
    "\n",
    "def calculate_aul(model, sentence, log_softmax):\n",
    "    '''\n",
    "    Given token ids of a sequence, return the averaged log probability of\n",
    "    unmasked sequence (AULA or AUL).\n",
    "    '''\n",
    "    tokens = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "    # Get the token IDs and attention mask\n",
    "    input_ids = tokens['input_ids'].to('mps')\n",
    "    output = model(input_ids, output_hidden_states=True)\n",
    "    logits = output.logits.squeeze(0)\n",
    "    log_probs = log_softmax(logits)\n",
    "    input_ids = input_ids.view(-1, 1).detach()\n",
    "    token_log_probs = log_probs.gather(1, input_ids)[1:-1]\n",
    "    sentence_log_prob = torch.mean(token_log_probs)\n",
    "    score = sentence_log_prob.item()\n",
    "\n",
    "    hidden_states = output.hidden_states[-1][:,1:-1].cpu()\n",
    "    hidden_state = torch.mean(hidden_states, 1).detach().numpy()\n",
    "\n",
    "    return score, hidden_state\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ce3bdf-cbad-4fde-98fd-e438f889060f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c985b8b3-e6bf-4f0b-8949-94a97a0ad4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cos_sim(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "959ccf14-0737-4b95-a639-d5fe4fe7f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_softmax = torch.nn.LogSoftmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e3be07a-2693-4c70-8992-08a3dcff6e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "caste_df = read_file(filename=\"../data/Caste.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67fc1cb6-2781-45c9-936e-ca434803e2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3409cb42c67f49e1bffd99d15fb29a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-multilingual-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81beaeef-40d5-45e9-9122-c4a059c8fc58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e0ce55d-7260-410e-b824-72d274009b8e",
   "metadata": {},
   "source": [
    "### Pretrain model on stereotypical statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ace3d8f-7ddd-4ba4-9072-e561dc8fc32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(data):\n",
    "    result = tokenizer(data)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7eadca76-d8be-4110-b9e6-e5e611e61da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_chunk_dataset(data):\n",
    "    chunk_size = 128\n",
    "    \n",
    "    # drop the last chunk if is smaller than the chunk size\n",
    "    total_length = len(data[\"input_ids\"])\n",
    "\n",
    "    # split the concatenated sentences into chunks using the total length\n",
    "    result = {k: [t[i: i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "    for k, t in data.items()}\n",
    "    \n",
    "\n",
    "    return pd.DataFrame(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2cd2ac0a-f527-4b18-9ec8-6b67599ca751",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = caste_df['Stereotypical'].apply(lambda x: tokenize_function(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "549247b6-8ca8-4191-9b0a-e41c6010c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = pd.concat(tokens.apply(lambda x : concat_chunk_dataset(x)).tolist()).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5ce9e92d-a843-419a-a577-9e530c19f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm_probability = .15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dd7450d7-a7b9-4025-b907-8dd39637281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_ds = Dataset.from_pandas(processed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e40344d9-1577-4693-8d0d-aa95cdae1b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 84\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 22\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsampled_dataset = stereo_ds.train_test_split(train_size=0.8, test_size=0.2, seed=42)\n",
    "downsampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f9fe0e0b-6208-44e9-b402-178f1d4f33fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"indic-bert-finetuned-stereo\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e98a768b-c35c-42ad-8486-f9c2d8f9e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=downsampled_dataset[\"train\"],\n",
    "    eval_dataset=downsampled_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "df980939-81cd-4ec1-9cc3-2f01ae414434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.282988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.223256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.593230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=33, training_loss=1.6709084944291548, metrics={'train_runtime': 44.372, 'train_samples_per_second': 5.679, 'train_steps_per_second': 0.744, 'total_flos': 1572385472352.0, 'train_loss': 1.6709084944291548, 'epoch': 3.0})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8c182a7c-8414-4142-9ae4-11f0db2d774d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 2.65\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b2fed8f8-f3ae-4c3a-b7ec-12dc3e1211e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9746655821800232,\n",
       " 'eval_runtime': 0.3336,\n",
       " 'eval_samples_per_second': 65.956,\n",
       " 'eval_steps_per_second': 8.994,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2c37b-ca09-4924-8a2e-33b0904af534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "20575228-a66a-40d4-abfe-0fabe2d58f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa8250d5-9f9c-445a-b8b3-a3d1710f5756",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-multilingual-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "49ebb71f-3a2d-4ce8-8f48-bf9d7855660f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias score (emb): 55.95\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stereo_inputs = [i for i in caste_df['Stereotypical']]\n",
    "antistereo_inputs = [i for i in caste_df['Anti-Stereotypical']]\n",
    "\n",
    "stereo_scores = []\n",
    "antistereo_scores = []\n",
    "stereo_embes = []\n",
    "antistereo_embes = []\n",
    "\n",
    "for i in stereo_inputs:\n",
    "    stereo_score, stereo_hidden_state = calculate_aul(model, i, log_softmax)\n",
    "    stereo_scores.append(stereo_score)\n",
    "    stereo_embes.append(stereo_hidden_state)\n",
    "\n",
    "for j in antistereo_inputs:\n",
    "    antistereo_score, antistereo_hidden_state = calculate_aul(model, j, log_softmax)\n",
    "    antistereo_scores.append(antistereo_score)\n",
    "    antistereo_embes.append(antistereo_hidden_state)\n",
    "\n",
    "stereo_scores = np.array(stereo_scores)\n",
    "stereo_scores = stereo_scores.reshape([-1, 1])\n",
    "antistereo_scores = np.array(antistereo_scores)\n",
    "antistereo_scores = antistereo_scores.reshape([1, -1])\n",
    "bias_scores = stereo_scores > antistereo_scores\n",
    "\n",
    "stereo_embes = np.concatenate(stereo_embes)\n",
    "antistereo_embes = np.concatenate(antistereo_embes)\n",
    "weights = cos_sim(stereo_embes, antistereo_embes.T)\n",
    "\n",
    "weighted_bias_scores = bias_scores * weights\n",
    "bias_score = np.sum(weighted_bias_scores) / np.sum(weights)\n",
    "print('bias score (emb):', round(bias_score * 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df7b75a-f8f7-4a3d-ba4d-aac0d753f5e4",
   "metadata": {},
   "source": [
    "\n",
    "mbert: 57.74\n",
    "mbert - finetune on stereo: 55.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaeb6c6-a84b-4ea1-bdd8-1774c2bbbc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d5916e-86f7-4125-af35-110d212f6140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b311565-fd11-4dd4-92bc-71b3cb60b13a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
